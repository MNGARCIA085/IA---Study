{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cb268cb",
   "metadata": {},
   "source": [
    "# <center><font color='blue'>SENTIMENT ANALYSIS: COVID</center></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ef0e5",
   "metadata": {},
   "source": [
    "## Tabla de contenido\n",
    "- [1 - Objetivos](#1)\n",
    "- [2 - Librerías necesarias](#2)\n",
    "- [3 - Carga y visualización de datos](#3)\n",
    "- [4 - Pre-procesamiento de datos](#4)\n",
    "    - [4.1. - Datos faltantes](#4.1)\n",
    "    - [4.2. - Data Categóricos](#4.2)\n",
    "    - [4.2. - Balanceo de clases](#4.3)\n",
    "    - [4.4. - Pre-Procesamiento especial para NLP](#4.4)\n",
    "- [5 - Modelos](#5)\n",
    "- [6 - Ajuste de hiperparámetros](#6)\n",
    "- [7 - Conclusiones](#7)\n",
    "- [8 - Referencias](#8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bd6143",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1. Objetivos\n",
    "\n",
    "Practicar con un problema de procesamiento del lenguaje natural.\n",
    "<br>\n",
    "Aquí, dado un conjunto de tweets, analizar si el sentimiento es positivo o negativo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ea4fd",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2. Librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b25607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# que no se impriman info y warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6215602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers,callbacks,models,Sequential,losses\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "import os,random\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2a8f2",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3. Carga y visualización de datos\n",
    "\n",
    "Tenemos 2 datasets, uno para entrenamiento y otro para test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0d5087c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_pandas = pd.read_csv('data/Corona_NLP_train.csv',encoding='latin-1')\n",
    "test_data_pandas = pd.read_csv('data/Corona_NLP_test.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9cd1da54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pandas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc18ed5",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## 4. Pre-procesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f705d5",
   "metadata": {},
   "source": [
    "<a name=\"4.1.\"></a>\n",
    "### 4.1. Datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e27a2e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos faltantes train:\n",
      " UserName            0\n",
      "ScreenName          0\n",
      "Location         8590\n",
      "TweetAt             0\n",
      "OriginalTweet       0\n",
      "Sentiment           0\n",
      "dtype: int64 \n",
      "\n",
      "Datos faltantes test:\n",
      " UserName           0\n",
      "ScreenName         0\n",
      "Location         834\n",
      "TweetAt            0\n",
      "OriginalTweet      0\n",
      "Sentiment          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Datos faltantes train:\\n {train_data_pandas.isnull().sum()} \\n')\n",
    "print(f'Datos faltantes test:\\n {test_data_pandas.isnull().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab1e77",
   "metadata": {},
   "source": [
    "Vemos que no hay datos faltantes en las columnas que nos interesan (OriginalTweet y Sentiment)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf849bb",
   "metadata": {},
   "source": [
    "<a name=\"4.2\"></a>\n",
    "### 4.2. Datos categóricos \n",
    "\n",
    "Nos interesaremos en las columnas OriginalTweet y Sentiment; a su vez veremos las distintas opciones de esta última columna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a07e94b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral', 'Positive', 'Extremely Negative', 'Negative',\n",
       "       'Extremely Positive'], dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pandas['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e5299",
   "metadata": {},
   "source": [
    "Convertiremos esta columna a valores numéricos; a su vez no nos interesa ser tan específicos respecto a si un sentimiento es postivo o extremadamente positivo, más bien distinguiremos entre positivo y negativo. Los neutrales los consideraremos positivos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5bc1e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'Extremely Negative':0,'Negative':0,'Neutral':1,'Positive':1,'Extremely Positive':1}\n",
    "train_data_pandas['Sentiment'] = train_data_pandas['Sentiment'].map(label_map)\n",
    "test_data_pandas['Sentiment'] = test_data_pandas['Sentiment'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58eb476",
   "metadata": {},
   "source": [
    "Chequeamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d725ef6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pandas['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ab485e",
   "metadata": {},
   "source": [
    "<a name=\"4.3\"></a>\n",
    "### 4.3.  Balanceo de clases\n",
    "\n",
    "Veamos si las clases están balanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "db59aa35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25759\n",
       "0    15398\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pandas['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c58118f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625871662171684"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25759/(25759+15398)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c3636a",
   "metadata": {},
   "source": [
    "Tenemos un desbalance moderado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0baa4bd",
   "metadata": {},
   "source": [
    "<a name=\"4.4\"> </a>\n",
    "### 4.4. Pre-procesamiento especial para NLP\n",
    "\n",
    "Vamos a pe-procesar el texto de OriginalTweet, para ello:\n",
    "\n",
    "\n",
    "- Quitaremos las stop-words\n",
    "- Quitaremos algunos caracteres especiales, como \"@\"\n",
    "- Aplicaremos Lemmatization\n",
    "\n",
    "\n",
    "<b>Nota:</b> Habría que quitar también las puntuaciones, llevar todo a minúscula y tokenizar, pero eso lo haremos luego con TextVectorization.\n",
    "\n",
    "Descargaremos e imprimiremos para ver las stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "063ff6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/marcos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "# View stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fb2995",
   "metadata": {},
   "source": [
    "También necesitaremos \"punkt\" y \"wordnet\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eb42d306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/marcos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/marcos/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8742b9e5",
   "metadata": {},
   "source": [
    "Quitamos las stop words y aplicaremos la lematización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "07e4e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar lematizador\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Función para quitar palabras de parada y lematizar un texto\n",
    "def preprocess_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Aplicar la función a la columna 'OriginalTweet' del dataset, tanto en train como test\n",
    "train_data_pandas['OriginalTweet'] = train_data_pandas['OriginalTweet'].apply(preprocess_text)\n",
    "test_data_pandas['OriginalTweet'] = test_data_pandas['OriginalTweet'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a03ef59",
   "metadata": {},
   "source": [
    "Además vamos a eliminar caracteres especiales, como @ y # (nos quedaremos con otros, como \"!\", pues pueden ser importantes para el significado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f7dec991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar arrobas en direcciones de correo electrónico o menciones\n",
    "def preprocess_text2(text):\n",
    "    return re.sub(r'[@#]', '', text) #&\n",
    "\n",
    "# lo aplicamos\n",
    "train_data_pandas['OriginalTweet'] = train_data_pandas['OriginalTweet'].apply(preprocess_text2)\n",
    "test_data_pandas['OriginalTweet'] = test_data_pandas['OriginalTweet'].apply(preprocess_text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2d04cb",
   "metadata": {},
   "source": [
    "Veamos cómo quedaron los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "035411d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         menyrbie  phil_gahan  chrisitv http : //t.co/...\n",
       "1        advice talk neighbour family exchange phone nu...\n",
       "2        coronavirus australia : woolworth give elderly...\n",
       "3        food stock one empty ... please , n't panic , ...\n",
       "4        , ready go supermarket  covid19 outbreak . 'm ...\n",
       "                               ...                        \n",
       "41152    airline pilot offering stock supermarket shelf...\n",
       "41153    response complaint provided citing covid-19 re...\n",
       "41154    know itâs getting tough  kameronwilds rationi...\n",
       "41155    wrong smell hand sanitizer starting turn ?  co...\n",
       "41156     tartiicat well new/used rift going $ 700.00 a...\n",
       "Name: OriginalTweet, Length: 41157, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pandas['OriginalTweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29455bc6",
   "metadata": {},
   "source": [
    "#### Dividimos en train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3ad75c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y validación\n",
    "train_data, val_data = train_test_split(train_data_pandas, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825dfbcf",
   "metadata": {},
   "source": [
    "#### Vamos ahora a crear los datasets para trabajar con tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2756717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el DataFrame de pandas en un objeto tf.data.Dataset\n",
    "# armo según lo que me interesa\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data['OriginalTweet'].values, \n",
    "                                              train_data['Sentiment'].values))\n",
    "\n",
    "\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((val_data['OriginalTweet'].values, \n",
    "                                              val_data['Sentiment'].values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6c3d0630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  b'unemployment claim made online virginia week : monday : 426 tuesday : 2,150 number going get bigger . http : //t.co/fueg2rl2dl'\n",
      "label:  0\n"
     ]
    }
   ],
   "source": [
    "# veo un dato de train y uno de test\n",
    "for example, label in train_dataset.take(1):\n",
    "  print('text: ', example.numpy())\n",
    "  print('label: ', label.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a6ae9b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetimos para test\n",
    "\n",
    "# Cargar el DataFrame de pandas en un objeto tf.data.Dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data_pandas['OriginalTweet'].values, \n",
    "                                                   test_data_pandas['Sentiment'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f9381",
   "metadata": {},
   "source": [
    "Definimos el tamaño del buffer y del lote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "130c6023",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f050ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "validation_dataset = validation_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d07a18",
   "metadata": {},
   "source": [
    "Veamos algunos ejemplos y sus etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e3547c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts:  [b'support initiative uae government contain spread covid-19 ,  lulumallfujairah temporarily closed mar 25th notice . period lulu hypermarket & amp ; pharmacy open . restaurant serve home delivery . http : //t.co/tygpevpams'\n",
      " b'lysol laundry sanitizer additive , crisp linen - 90oz http : //t.co/4nxnk307wx  coronavirus  covid_19  covid19 http : //t.co/tkwhznbhwm'\n",
      " b'read tip keep  coronavirus  scammer bay . http : //t.co/am6qpqx249 remain vigilant  cyberaware  cybersecurity http : //t.co/qhcpdgsdrt']\n",
      "\n",
      "labels: , [1 1 1]\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "  print(f'texts:  {example.numpy()[:3]}\\n')\n",
    "  print(f'labels: , {label.numpy()[:3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40570385",
   "metadata": {},
   "source": [
    "Ahora crearemos y aplicaremos una capa llamada <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization\" target='_blanck'>TextVectorization</a>, que quitará las puntuaciones, pasará todo a minúsculas y tokenizará:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ddb36375",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "max_length = 45 # max length our sequences will be (e.g. how many words from a Tweet does a model see?)\n",
    "\n",
    "\n",
    "encoder = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)\n",
    "\n",
    "# Fit the text vectorizer instance to the training data using the adapt() method\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee364817",
   "metadata": {},
   "source": [
    "A continuación se muestran los primeros 20 tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ada68128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'http', 'coronavirus', 'covid19', 'price', 'store',\n",
       "       'supermarket', 'food', 'grocery', 'people', 'amp', 'consumer',\n",
       "       '19', 'covid', 'shopping', 's', 'online', 'need', 'time'],\n",
       "      dtype='<U27')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d7f75",
   "metadata": {},
   "source": [
    "Ahora que el vocabulario está configurado, la capa puede codificar el texto en índices. Los tensores de índices son rellenados con 0s para que tengan el tamaño de la secuencia más larga en el lote.\n",
    "\n",
    "Veamos un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c80a2ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 127, 1868, 2314,   97, 1641,   91,    4,    1,  831,  217, 1895,\n",
       "        5144,  840,  530, 4997, 2579,   11,  294,  146,  189, 1219,   28,\n",
       "          57,    2,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [1544, 2331,   30, 4229, 4391, 5329,    1,    2,    1,    3,    4,\n",
       "           4,    2,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [ 131,  270,   61,    3,  521, 1672,    2,    1,  502, 2683,    1,\n",
       "        3447,    2,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_example = encoder(example)[:3].numpy()\n",
    "encoded_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3741a6cf",
   "metadata": {},
   "source": [
    "Vemos que rellena con 0s hasta tener siempre un largo de 45.\n",
    "\n",
    "Con esta configuración, el proceso no es completamente reversible (no hay un mapeo uno a uno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5d873bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  b'support initiative uae government contain spread covid-19 ,  lulumallfujairah temporarily closed mar 25th notice . period lulu hypermarket & amp ; pharmacy open . restaurant serve home delivery . http : //t.co/tygpevpams'\n",
      "Round-trip:  support initiative uae government contain spread covid19 [UNK] temporarily closed mar 25th notice period lulu hypermarket amp pharmacy open restaurant serve home delivery http [UNK]                    \n",
      "\n",
      "Original:  b'lysol laundry sanitizer additive , crisp linen - 90oz http : //t.co/4nxnk307wx  coronavirus  covid_19  covid19 http : //t.co/tkwhznbhwm'\n",
      "Round-trip:  lysol laundry sanitizer additive crisp linen [UNK] http [UNK] coronavirus covid19 covid19 http [UNK]                               \n",
      "\n",
      "Original:  b'read tip keep  coronavirus  scammer bay . http : //t.co/am6qpqx249 remain vigilant  cyberaware  cybersecurity http : //t.co/qhcpdgsdrt'\n",
      "Round-trip:  read tip keep coronavirus scammer bay http [UNK] remain vigilant [UNK] cybersecurity http [UNK]                               \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(3):\n",
    "  print(\"Original: \", example[n].numpy())\n",
    "  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af48ea7",
   "metadata": {},
   "source": [
    "Puede observarse que hay muchos tokens desconocidos ([UNK])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbbdb90",
   "metadata": {},
   "source": [
    "Finalmente, aplicaremos una capa de embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a9a0f1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x7fd84d833ee0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, # set the input shape; size of our vocabulary\n",
    "                                 output_dim=128, # set the size of the embedding vector\n",
    "                                 embeddings_initializer=\"uniform\", # default, initialize embedding vectors randomly\n",
    "                                 input_length=max_length # how long is each input\n",
    "                             )\n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf581ab",
   "metadata": {},
   "source": [
    "<a name=\"5\"> </a>\n",
    "## MODELOS\n",
    "\n",
    "Probaremos distinos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee0fc1b",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "Es un modelo muy simple con Scikit Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a1bcc6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-dimensional strings\n",
    "x = encoder(inputs) # turn the input text into numbers \n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "acacf449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "515/515 [==============================] - 9s 17ms/step - loss: 0.2312 - accuracy: 0.9169 - val_loss: 0.3703 - val_accuracy: 0.8543\n",
      "Epoch 2/5\n",
      "515/515 [==============================] - 9s 17ms/step - loss: 0.2149 - accuracy: 0.9230 - val_loss: 0.3793 - val_accuracy: 0.8545\n",
      "Epoch 3/5\n",
      "515/515 [==============================] - 9s 17ms/step - loss: 0.2018 - accuracy: 0.9292 - val_loss: 0.3918 - val_accuracy: 0.8542\n",
      "Epoch 4/5\n",
      "515/515 [==============================] - 10s 20ms/step - loss: 0.1911 - accuracy: 0.9339 - val_loss: 0.4009 - val_accuracy: 0.8513\n",
      "Epoch 5/5\n",
      "515/515 [==============================] - 11s 21ms/step - loss: 0.1817 - accuracy: 0.9367 - val_loss: 0.4127 - val_accuracy: 0.8525\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "history_1 = model_1.fit(train_dataset,\n",
    "                        #train_labels, \n",
    "                        epochs=5,\n",
    "                        validation_data=validation_dataset)\n",
    "                        #callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                        #                                       experiment_name=\"model_1_dense\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c45c72e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0 1 1 0 1 1 0 0 1 1 1 0 1 1 0 1 0 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 1 0 1 1 0\n",
      " 1 0 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 0 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1\n",
      " 0 0 1 0 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0\n",
      " 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 1\n",
      " 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 0 1 0 1 1 0 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 0 1 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1\n",
      " 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1\n",
      " 1 0 0 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 1\n",
      " 0 0 1 1 0 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1\n",
      " 0 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 1\n",
      " 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 0 0 1 1 0 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0\n",
      " 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1\n",
      " 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1\n",
      " 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1\n",
      " 0 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 0 1\n",
      " 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 0 1 0\n",
      " 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 1 1 0 0\n",
      " 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1\n",
      " 1 0 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1\n",
      " 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0 1 1 1 1\n",
      " 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1\n",
      " 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0\n",
      " 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 0 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0\n",
      " 0 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 0 1 0 1\n",
      " 1 0 1 1 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0\n",
      " 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 0 1 1 0\n",
      " 1 1 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 0 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 0 1 1 0 1 0 1 1 0 0 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1\n",
      " 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1\n",
      " 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0\n",
      " 1 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1\n",
      " 0 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 0 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 1 1\n",
      " 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 0 0 1 1 1 1\n",
      " 1 0 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 0 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 0\n",
      " 1 0 1 1 1 1 0 1 1 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 0 1 1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1\n",
      " 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 0 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1\n",
      " 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0\n",
      " 1 1 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1\n",
      " 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 0\n",
      " 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0\n",
      " 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 1 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0\n",
      " 0 1 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1\n",
      " 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 1 0 0 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1\n",
      " 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0\n",
      " 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 0 0\n",
      " 1 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 0 0 1 0 0 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 1 1\n",
      " 1 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 1 0\n",
      " 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1\n",
      " 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 1 1\n",
      " 0 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 0 0 0 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 1\n",
      " 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 1 0 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 0\n",
      " 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 1 0 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1\n",
      " 1 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 0 1 1 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1\n",
      " 1 1 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 0\n",
      " 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0\n",
      " 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 0 0 0 1 0 1 1 1\n",
      " 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0\n",
      " 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1\n",
      " 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 1 0 0 1 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 1 0 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 1 1 0 1\n",
      " 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 0 0 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1\n",
      " 1 0 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0 0 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1\n",
      " 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 0 1 1 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1\n",
      " 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 1 1 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 0 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 0 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0\n",
      " 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 0\n",
      " 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0\n",
      " 1 0 0 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1\n",
      " 1 0 0 0 0 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 1 1 1 1\n",
      " 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 0\n",
      " 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 0 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1\n",
      " 0 1 0 0 0 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 0 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 1 1 1 0 0 0 1 0\n",
      " 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1\n",
      " 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1\n",
      " 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1\n",
      " 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 0 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1\n",
      " 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 0 0 1 1 1 0 0 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 1 1 0\n",
      " 0 1 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 0 0 1\n",
      " 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0 0 0\n",
      " 1 1 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1\n",
      " 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 0 1\n",
      " 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1\n",
      " 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 1 1 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 0\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 0 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1\n",
      " 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 1 0 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0 1 0\n",
      " 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 0 0 0 1 0\n",
      " 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0\n",
      " 0 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 1 1\n",
      " 0 0 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 0 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1\n",
      " 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1\n",
      " 0 1 1 1 0 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1 1 1 0 0 0\n",
      " 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0\n",
      " 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1\n",
      " 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 1 1\n",
      " 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 0 1 1 0 1 0 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0 1 1 0 0\n",
      " 0 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0\n",
      " 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0\n",
      " 1 0 0 0 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0\n",
      " 0 1 1 1 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 0 1\n",
      " 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 1 0 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 1\n",
      " 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
      " 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0\n",
      " 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[1 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 0 0\n",
      " 1 1 1], shape=(40,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for x,y in validation_dataset:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "60b5e366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta: [1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0\n",
      " 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1]\n",
      "Etiqueta: [0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1\n",
      " 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1]\n",
      "Etiqueta: [1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 1 0]\n",
      "Etiqueta: [1 0 1 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
      " 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1]\n",
      "Etiqueta: [0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 1 1 0\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 0 1]\n",
      "Etiqueta: [1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 0 1\n",
      " 1 1 0 1 1 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1]\n",
      "Etiqueta: [1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 1 1\n",
      " 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Etiqueta: [0 1 1 0 0 1 1 0 1 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1]\n",
      "Etiqueta: [1 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 0 1\n",
      " 0 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0 0]\n",
      "Etiqueta: [1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 0 1\n",
      " 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1]\n",
      "Etiqueta: [1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1\n",
      " 0 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1]\n",
      "Etiqueta: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 1 1\n",
      " 0 0 0 1 0 0 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0]\n",
      "Etiqueta: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0\n",
      " 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1]\n",
      "Etiqueta: [1 1 1 0 1 0 1 0 1 1 0 1 1 1 0 0 1 0 1 1 0 1 0 1 1 1 1 0 1 0 1 0 1 0 1 1 0\n",
      " 0 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0]\n",
      "Etiqueta: [1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0\n",
      " 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1]\n",
      "Etiqueta: [0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
      " 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1]\n",
      "Etiqueta: [1 1 1 0 1 1 1 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1\n",
      " 1 1 1 1 0 1 1 0 1 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1]\n",
      "Etiqueta: [0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1\n",
      " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1]\n",
      "Etiqueta: [0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1]\n",
      "Etiqueta: [1 1 1 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 1 0 1 1 0 0 0\n",
      " 1 0 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1]\n",
      "Etiqueta: [1 0 1 1 0 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 0\n",
      " 1 1 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1 1]\n",
      "Etiqueta: [1 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1\n",
      " 1 1 1 0 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1]\n",
      "Etiqueta: [1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1\n",
      " 1 1 0 0 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 0 0]\n",
      "Etiqueta: [1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1]\n",
      "Etiqueta: [1 1 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 1 0 1 1 1 1 0 0\n",
      " 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0]\n",
      "Etiqueta: [1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 1\n",
      " 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0]\n",
      "Etiqueta: [1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1\n",
      " 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1 0 1 1]\n",
      "Etiqueta: [1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 1 1\n",
      " 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0]\n",
      "Etiqueta: [1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1\n",
      " 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 0]\n",
      "Etiqueta: [0 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0\n",
      " 0 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0]\n",
      "Etiqueta: [1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 1 1 0\n",
      " 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1]\n",
      "Etiqueta: [1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0\n",
      " 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0]\n",
      "Etiqueta: [1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1\n",
      " 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1]\n",
      "Etiqueta: [0 1 0 1 1 1 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1\n",
      " 1 1 1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1]\n",
      "Etiqueta: [1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0\n",
      " 0 0 1 0 1 1 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 0 0 1 1]\n",
      "Etiqueta: [0 0 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 1 0 0 0 0 0 1\n",
      " 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1]\n",
      "Etiqueta: [0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0\n",
      " 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 1 1]\n",
      "Etiqueta: [1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 0]\n",
      "Etiqueta: [0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 0 0 0 0\n",
      " 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0]\n",
      "Etiqueta: [1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0 1 0 1 1 1]\n",
      "Etiqueta: [1 1 1 1 0 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1\n",
      " 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 1]\n",
      "Etiqueta: [1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1\n",
      " 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "Etiqueta: [0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1\n",
      " 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1]\n",
      "Etiqueta: [0 0 1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0\n",
      " 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1]\n",
      "Etiqueta: [0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 0\n",
      " 0 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1]\n",
      "Etiqueta: [0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0]\n",
      "Etiqueta: [1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0\n",
      " 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 1]\n",
      "Etiqueta: [0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 1 1 1 1 1\n",
      " 0 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 0 0 1 0 0 1]\n",
      "Etiqueta: [1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0]\n",
      "Etiqueta: [0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 0 1 1 0 0\n",
      " 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1]\n",
      "Etiqueta: [1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1\n",
      " 1 1 0 0 0 0 1 1 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 0 1]\n",
      "Etiqueta: [0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0]\n",
      "Etiqueta: [1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0\n",
      " 0 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0]\n",
      "Etiqueta: [0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1]\n",
      "Etiqueta: [1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 1 1 1 0\n",
      " 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0]\n",
      "Etiqueta: [0 0 0 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 1\n",
      " 1 1 0 1 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 0]\n",
      "Etiqueta: [0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 0\n",
      " 1 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0]\n",
      "Etiqueta: [1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 0 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 1 1 0 0]\n",
      "Etiqueta: [1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1\n",
      " 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1 0 1 1 1]\n",
      "Etiqueta: [1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 0]\n",
      "Etiqueta: [1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0\n",
      " 1 0 0 0 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1]\n",
      "Etiqueta: [0 0 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 0\n",
      " 1 1 0 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 0 1 0]\n",
      "Etiqueta: [0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0\n",
      " 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 1]\n",
      "Etiqueta: [0 1 0 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 0 0 1 1 1\n",
      " 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 1 0 1 0]\n",
      "Etiqueta: [1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0\n",
      " 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 1 1]\n",
      "Etiqueta: [1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0\n",
      " 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1]\n",
      "Etiqueta: [1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1\n",
      " 1 0 1 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0]\n",
      "Etiqueta: [0 0 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1\n",
      " 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1]\n",
      "Etiqueta: [0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1]\n",
      "Etiqueta: [1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1\n",
      " 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1]\n",
      "Etiqueta: [1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1]\n",
      "Etiqueta: [0 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0\n",
      " 0 0 1 0 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0]\n",
      "Etiqueta: [0 1 1 1 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 1\n",
      " 0 1 1 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1]\n",
      "Etiqueta: [1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 1 0 0 1 0 0 0 0 1 1 1 1 1 1\n",
      " 1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 0 1]\n",
      "Etiqueta: [0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0\n",
      " 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1]\n",
      "Etiqueta: [1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0\n",
      " 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 1 0]\n",
      "Etiqueta: [0 1 1 1 0 1 1 1 0 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 0\n",
      " 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1]\n",
      "Etiqueta: [1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 0 1 0 1 1 1\n",
      " 0 0 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1]\n",
      "Etiqueta: [0 0 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0\n",
      " 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1]\n",
      "Etiqueta: [0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1\n",
      " 1 1 0 0 1 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0]\n",
      "Etiqueta: [0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 0 0 1 1]\n",
      "Etiqueta: [0 1 0 0 0 1 0 1 0 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1]\n",
      "Etiqueta: [1 0 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 1 0 1 1 0 1\n",
      " 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 1 0 0 1 1]\n",
      "Etiqueta: [0 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1\n",
      " 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1]\n",
      "Etiqueta: [1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 1 1 0\n",
      " 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 1 0]\n",
      "Etiqueta: [1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1\n",
      " 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1]\n",
      "Etiqueta: [0 1 1 1 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1\n",
      " 1 1 0 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 0 1 0 1 1 0]\n",
      "Etiqueta: [1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 0 0 1\n",
      " 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1]\n",
      "Etiqueta: [0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 1 1 0 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 0 0]\n",
      "Etiqueta: [1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 0\n",
      " 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 0 0]\n",
      "Etiqueta: [1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1\n",
      " 1 1 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 1 0 0 1]\n",
      "Etiqueta: [0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 1 0 1\n",
      " 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1 0 0 1]\n",
      "Etiqueta: [1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1\n",
      " 1 1 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 1 1 0 1]\n",
      "Etiqueta: [0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1\n",
      " 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 1]\n",
      "Etiqueta: [1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0]\n",
      "Etiqueta: [0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 1 1 0 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1]\n",
      "Etiqueta: [1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 1]\n",
      "Etiqueta: [1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 1\n",
      " 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 0 0]\n",
      "Etiqueta: [1 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1]\n",
      "Etiqueta: [1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1]\n",
      "Etiqueta: [0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0]\n",
      "Etiqueta: [0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 1 0 1 0 0 1\n",
      " 0 0 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
      "Etiqueta: [0 1 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1]\n",
      "Etiqueta: [1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1\n",
      " 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1]\n",
      "Etiqueta: [0 0 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 1 0 1\n",
      " 1 0 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 0]\n",
      "Etiqueta: [1 1 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 1]\n",
      "Etiqueta: [1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 1]\n",
      "Etiqueta: [1 0 0 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 1 0\n",
      " 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1]\n",
      "Etiqueta: [1 1 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1\n",
      " 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 1 1]\n",
      "Etiqueta: [1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0 1\n",
      " 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 0 0 1 1 1]\n",
      "Etiqueta: [1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1\n",
      " 0 0 1 1 0 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0]\n",
      "Etiqueta: [1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 1 0]\n",
      "Etiqueta: [1 1 0 0 0 1 1 0 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0\n",
      " 0 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1]\n",
      "Etiqueta: [1 1 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 0 1 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 0]\n",
      "Etiqueta: [0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1\n",
      " 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 0 1]\n",
      "Etiqueta: [1 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1]\n",
      "Etiqueta: [0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
      "Etiqueta: [0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 1\n",
      " 0 1 0 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0]\n",
      "Etiqueta: [0 1 0 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1]\n",
      "Etiqueta: [1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 1\n",
      " 0 0 1 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 0 1]\n",
      "Etiqueta: [0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 0 1 1]\n",
      "Etiqueta: [0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1]\n",
      "Etiqueta: [0 1 0 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1 0\n",
      " 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0]\n",
      "Etiqueta: [1 1 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1\n",
      " 0 0 1 0 0 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1]\n",
      "Etiqueta: [1 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0\n",
      " 0 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0]\n",
      "Etiqueta: [0 1 1 1 1 0 1 1 1 0 0 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1\n",
      " 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0]\n",
      "Etiqueta: [0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1\n",
      " 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 1]\n",
      "Etiqueta: [0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1\n",
      " 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1]\n",
      "Etiqueta: [1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1\n",
      " 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "for text, label in validation_dataset:\n",
    "    print(\"Etiqueta:\", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "69a57782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.8344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46907660365104675, 0.8343865275382996]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c3a2f84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sample_text = ('The movie was cool. The animation and the graphics '\n",
    "               'were out of this world. I would recommend this movie')\n",
    "predictions = model_1.predict(np.array([sample_text]))\n",
    "\n",
    "predictions\n",
    "\n",
    "\n",
    "binary_prediction = 1 if predictions[0, 0] > 0.5 else 0\n",
    "\n",
    "\n",
    "binary_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0443b552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "[array([0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1]), array([0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1]), array([0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "       0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1]), array([1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0]), array([1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
      "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1]), array([1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
      "       1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]), array([1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "       1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1]), array([0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "       0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1]), array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]), array([0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]), array([1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1]), array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0]), array([0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
      "       1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1]), array([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0]), array([1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "       0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), array([1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1]), array([0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1]), array([0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0]), array([1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0]), array([1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0]), array([0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
      "       0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0]), array([1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0]), array([1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "       0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1]), array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
      "       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0]), array([0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "       0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1]), array([0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0]), array([0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "       0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1]), array([1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "       0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0]), array([1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1]), array([1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "       1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1]), array([0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1]), array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "       0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1]), array([1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "       0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1]), array([1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1]), array([1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "       1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0]), array([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1]), array([1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "       1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1]), array([1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0]), array([1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0]), array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "       1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1]), array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0]), array([1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
      "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1]), array([1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "       0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1]), array([1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1]), array([0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1]), array([0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "       1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0]), array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "       0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0]), array([0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1]), array([1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "       1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]), array([1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "       0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1]), array([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "       1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1]), array([0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1]), array([0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), array([1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]), array([1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "       0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0]), array([0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "       0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0]), array([0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "       0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1]), array([1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0]), array([1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
      "       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1]), array([1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0]), array([1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1]), array([1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "       0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1]), array([1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "       1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0]), array([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "       0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1]), array([1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0]), array([1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0]), array([1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1]), array([0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1]), array([1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "       0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0]), array([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0]), array([1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0]), array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0]), array([1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1]), array([1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0]), array([1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "       1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "       0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1]), array([1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1]), array([0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1]), array([1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1]), array([0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
      "       1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1]), array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]), array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]), array([0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "       1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1]), array([0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
      "       0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1]), array([0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0]), array([1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "       1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0]), array([0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]), array([1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1]), array([1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "       1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]), array([1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1]), array([1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "       1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "       0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1]), array([0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0]), array([1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1]), array([1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "       1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1]), array([0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "       1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "       1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1]), array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "       1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0]), array([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "       1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0]), array([1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1]), array([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0]), array([0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1]), array([1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "       0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0]), array([1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "       1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0]), array([1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0]), array([0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1]), array([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1]), array([1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "       1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "       0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), array([1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]), array([0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
      "       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1]), array([0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1]), array([0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1]), array([1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1]), array([1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "       0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1]), array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "       0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), array([1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1]), array([1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "       1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
      "       1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1]), array([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "       0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0]), array([1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0]), array([1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0]), array([0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0]), array([1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "       0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1]), array([0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0]), array([1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "       1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1]), array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]), array([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
      "       0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0]), array([1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "       0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1]), array([1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "       1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0]), array([1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1]), array([0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "       0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1]), array([1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Supongamos que ya has entrenado tu modelo y tienes un modelo llamado 'modelo_entrenado'\n",
    "\n",
    "# Crear listas para almacenar las etiquetas verdaderas y las predicciones del modelo\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Iterar sobre el conjunto de validación y realizar predicciones\n",
    "for text, label in validation_dataset:\n",
    "    # Preprocesar el texto (si es necesario)\n",
    "    # ...\n",
    "    \n",
    "    \n",
    "    print(type(text))\n",
    "    \n",
    "\n",
    "\n",
    "    # Realizar la predicción con el modelo entrenado\n",
    "    predictions = model_1.predict(text.numpy(),verbose=0)\n",
    "    \n",
    "    binary_prediction = 1 if predictions[0, 0] > 0.5 else 0\n",
    "    \n",
    "    \n",
    "    #sample_text = ('The movie was cool. The animation and the graphics '\n",
    "    #               'were out of this world. I would recommend this movie')\n",
    "    #predictions = model_1.predict(np.array([sample_text]))\n",
    "\n",
    "    # Convertir las predicciones a etiquetas (por ejemplo, usando argmax)\n",
    "    predicted_label = tf.argmax(predictions).numpy()\n",
    "\n",
    "    # Almacenar las etiquetas verdaderas y las predicciones\n",
    "    true_labels.append(label.numpy())\n",
    "    \n",
    "    predicted_labels.append(binary_prediction)\n",
    "    \n",
    "    #break\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "predicted_labels    \n",
    "\n",
    "\n",
    "\n",
    "print(true_labels)\n",
    "\n",
    "# Calcular la matriz de confusión y otras métricas\n",
    "#conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "#classification_rep = classification_report(true_labels, predicted_labels)\n",
    "\n",
    "# Imprimir la matriz de confusión y el informe de clasificación\n",
    "#print(\"Matriz de Confusión:\")\n",
    "#print(conf_matrix)\n",
    "\n",
    "#print(\"\\nInforme de Clasificación:\")\n",
    "#print(classification_rep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "44ff188c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.9017605]]\n",
      "Predicción: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "EN LA INFERENCIA NO NECESITO APLICAR\n",
    "ENCODE Y EMBEDDING XQ LO HAGO\n",
    "DIRECTAMENTE EN EL MODELO\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Supongamos que ya has definido tu modelo (model_1), el encoder y la capa de embedding\n",
    "\n",
    "# Texto de entrada para hacer una predicción\n",
    "input_text = \"some text\"\n",
    "\n",
    "\n",
    "\n",
    "input_text = preprocess_text(input_text)\n",
    "\n",
    "input_text = preprocess_text2(input_text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pred = model_1.predict(np.array([input_text]))\n",
    "\n",
    "print(pred)\n",
    "\n",
    "\n",
    "\n",
    "# Convertir la salida a una predicción binaria (0 o 1) si es necesario\n",
    "binary_prediction = 1 if pred[0, 0] > 0.5 else 0\n",
    "\n",
    "# Imprimir la predicción\n",
    "print(\"Predicción:\", binary_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a5239d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
