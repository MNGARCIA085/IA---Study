{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cb268cb",
   "metadata": {},
   "source": [
    "# <center><font color='blue'>SENTIMENT ANALYSIS: COVID</center></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ef0e5",
   "metadata": {},
   "source": [
    "## Tabla de contenido\n",
    "- [1 - Objetivos](#1)\n",
    "- [2 - Librerías necesarias](#2)\n",
    "- [3 - Carga y visualización de datos](#3)\n",
    "- [4 - Pre-procesamiento de datos](#4)\n",
    "    - [4.1. - Datos faltantes](#4.1)\n",
    "    - [4.2. - Data Categóricos](#4.2)\n",
    "    - [4.2. - Balanceo de clases](#4.3)\n",
    "    - [4.4. - Pre-Procesamiento especial para NLP](#4.4)\n",
    "- [5 - Modelos](#5)\n",
    "- [6 - Ajuste de hiperparámetros](#6)\n",
    "- [7 - Conclusiones](#7)\n",
    "- [8 - Referencias](#8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bd6143",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1. Objetivos\n",
    "\n",
    "Practicar con un problema de procesamiento del lenguaje natural.\n",
    "<br>\n",
    "Aquí, dado un conjunto de tweets, analizar si el sentimiento es positivo o negativo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ea4fd",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2. Librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c5b25607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# que no se impriman info y warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e6215602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers,callbacks,models,Sequential,losses\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "import os,random\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import tensorflow_hub as hub\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2a8f2",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3. Carga y visualización de datos\n",
    "\n",
    "Tenemos 2 datasets, uno para entrenamiento y otro para test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0d5087c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_pandas = pd.read_csv('data/Corona_NLP_train.csv',encoding='latin-1')\n",
    "test_data_pandas = pd.read_csv('data/Corona_NLP_test.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9cd1da54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pandas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc18ed5",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## 4. Pre-procesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f705d5",
   "metadata": {},
   "source": [
    "<a name=\"4.1.\"></a>\n",
    "### 4.1. Datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e27a2e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos faltantes train:\n",
      " UserName            0\n",
      "ScreenName          0\n",
      "Location         8590\n",
      "TweetAt             0\n",
      "OriginalTweet       0\n",
      "Sentiment           0\n",
      "dtype: int64 \n",
      "\n",
      "Datos faltantes test:\n",
      " UserName           0\n",
      "ScreenName         0\n",
      "Location         834\n",
      "TweetAt            0\n",
      "OriginalTweet      0\n",
      "Sentiment          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Datos faltantes train:\\n {train_data_pandas.isnull().sum()} \\n')\n",
    "print(f'Datos faltantes test:\\n {test_data_pandas.isnull().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab1e77",
   "metadata": {},
   "source": [
    "Vemos que no hay datos faltantes en las columnas que nos interesan (OriginalTweet y Sentiment)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf849bb",
   "metadata": {},
   "source": [
    "<a name=\"4.2\"></a>\n",
    "### 4.2. Datos categóricos \n",
    "\n",
    "Nos interesaremos en las columnas OriginalTweet y Sentiment; a su vez veremos las distintas opciones de esta última columna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a07e94b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral', 'Positive', 'Extremely Negative', 'Negative',\n",
       "       'Extremely Positive'], dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pandas['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e5299",
   "metadata": {},
   "source": [
    "Convertiremos esta columna a valores numéricos; a su vez no nos interesa ser tan específicos respecto a si un sentimiento es postivo o extremadamente positivo, más bien distinguiremos entre positivo y negativo. Los neutrales los consideraremos positivos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5bc1e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'Extremely Negative':0,'Negative':0,'Neutral':1,'Positive':1,'Extremely Positive':1}\n",
    "train_data_pandas['Sentiment'] = train_data_pandas['Sentiment'].map(label_map)\n",
    "test_data_pandas['Sentiment'] = test_data_pandas['Sentiment'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58eb476",
   "metadata": {},
   "source": [
    "Chequeamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d725ef6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pandas['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ab485e",
   "metadata": {},
   "source": [
    "<a name=\"4.3\"></a>\n",
    "### 4.3.  Balanceo de clases\n",
    "\n",
    "Veamos si las clases están balanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "db59aa35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25759\n",
       "0    15398\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pandas['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c58118f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625871662171684"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25759/(25759+15398)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c3636a",
   "metadata": {},
   "source": [
    "Tenemos un desbalance moderado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0baa4bd",
   "metadata": {},
   "source": [
    "<a name=\"4.4\"> </a>\n",
    "### 4.4. Pre-procesamiento especial para NLP\n",
    "\n",
    "Vamos a pe-procesar el texto de OriginalTweet, para ello:\n",
    "\n",
    "\n",
    "- Quitaremos las stop-words\n",
    "- Quitaremos algunos caracteres especiales, como \"@\"\n",
    "- Aplicaremos Lemmatization\n",
    "\n",
    "\n",
    "<b>Nota:</b> Habría que quitar también las puntuaciones, llevar todo a minúscula y tokenizar, pero eso lo haremos luego con TextVectorization.\n",
    "\n",
    "Descargaremos e imprimiremos para ver las stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "063ff6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/marcos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "# View stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fb2995",
   "metadata": {},
   "source": [
    "También necesitaremos \"punkt\" y \"wordnet\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eb42d306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/marcos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/marcos/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8742b9e5",
   "metadata": {},
   "source": [
    "Quitamos las stop words y aplicaremos la lematización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "07e4e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar lematizador\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Función para quitar palabras de parada y lematizar un texto\n",
    "def preprocess_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Aplicar la función a la columna 'OriginalTweet' del dataset, tanto en train como test\n",
    "train_data_pandas['OriginalTweet'] = train_data_pandas['OriginalTweet'].apply(preprocess_text)\n",
    "test_data_pandas['OriginalTweet'] = test_data_pandas['OriginalTweet'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a03ef59",
   "metadata": {},
   "source": [
    "Además vamos a eliminar caracteres especiales, como @ y # (nos quedaremos con otros, como \"!\", pues pueden ser importantes para el significado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f7dec991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar arrobas en direcciones de correo electrónico o menciones\n",
    "def preprocess_text2(text):\n",
    "    return re.sub(r'[@#]', '', text) #&\n",
    "\n",
    "# lo aplicamos\n",
    "train_data_pandas['OriginalTweet'] = train_data_pandas['OriginalTweet'].apply(preprocess_text2)\n",
    "test_data_pandas['OriginalTweet'] = test_data_pandas['OriginalTweet'].apply(preprocess_text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2d04cb",
   "metadata": {},
   "source": [
    "Veamos cómo quedaron los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "035411d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         menyrbie  phil_gahan  chrisitv http : //t.co/...\n",
       "1        advice talk neighbour family exchange phone nu...\n",
       "2        coronavirus australia : woolworth give elderly...\n",
       "3        food stock one empty ... please , n't panic , ...\n",
       "4        , ready go supermarket  covid19 outbreak . 'm ...\n",
       "                               ...                        \n",
       "41152    airline pilot offering stock supermarket shelf...\n",
       "41153    response complaint provided citing covid-19 re...\n",
       "41154    know itâs getting tough  kameronwilds rationi...\n",
       "41155    wrong smell hand sanitizer starting turn ?  co...\n",
       "41156     tartiicat well new/used rift going $ 700.00 a...\n",
       "Name: OriginalTweet, Length: 41157, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pandas['OriginalTweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29455bc6",
   "metadata": {},
   "source": [
    "#### Dividimos en train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3ad75c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y validación\n",
    "train_data, val_data = train_test_split(train_data_pandas, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825dfbcf",
   "metadata": {},
   "source": [
    "#### Vamos ahora a crear los datasets para trabajar con tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2756717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el DataFrame de pandas en un objeto tf.data.Dataset\n",
    "# armo según lo que me interesa\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data['OriginalTweet'].values, \n",
    "                                              train_data['Sentiment'].values))\n",
    "\n",
    "\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((val_data['OriginalTweet'].values, \n",
    "                                              val_data['Sentiment'].values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6c3d0630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  b'unemployment claim made online virginia week : monday : 426 tuesday : 2,150 number going get bigger . http : //t.co/fueg2rl2dl'\n",
      "label:  0\n"
     ]
    }
   ],
   "source": [
    "# veo un dato de train y uno de test\n",
    "for example, label in train_dataset.take(1):\n",
    "  print('text: ', example.numpy())\n",
    "  print('label: ', label.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a6ae9b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetimos para test\n",
    "\n",
    "# Cargar el DataFrame de pandas en un objeto tf.data.Dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data_pandas['OriginalTweet'].values, \n",
    "                                                   test_data_pandas['Sentiment'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f9381",
   "metadata": {},
   "source": [
    "Definimos el tamaño del buffer y del lote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "130c6023",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f050ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "validation_dataset = validation_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d07a18",
   "metadata": {},
   "source": [
    "Veamos algunos ejemplos y sus etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e3547c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts:  [b' ukenterprise speaking ur staff & amp ; asked shutdown affecting business . said lot people cancelling booking . checked online price gone . supply + demand ? picked another operator since ur keen putting peop'\n",
      " b'begun .  france  supermarket  coronavirus  lockdown http : //t.co/ogntm76ayc'\n",
      " b'due  coronavirus university shutdown , build small lab garage finish master project one student . turn prefect time consumer kid ? ? ?  earwigscience  irbi_tours http : //t.co/njgw2xuj0t']\n",
      "\n",
      "labels: , [1 1 1]\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "  print(f'texts:  {example.numpy()[:3]}\\n')\n",
    "  print(f'labels: , {label.numpy()[:3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40570385",
   "metadata": {},
   "source": [
    "Ahora crearemos y aplicaremos una capa llamada <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization\" target='_blanck'>TextVectorization</a>, que quitará las puntuaciones, pasará todo a minúsculas y tokenizará:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ddb36375",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "max_length = 45 # max length our sequences will be (e.g. how many words from a Tweet does a model see?)\n",
    "\n",
    "\n",
    "encoder = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)\n",
    "\n",
    "# Fit the text vectorizer instance to the training data using the adapt() method\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee364817",
   "metadata": {},
   "source": [
    "A continuación se muestran los primeros 20 tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ada68128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'http', 'coronavirus', 'covid19', 'price', 'store',\n",
       "       'supermarket', 'food', 'grocery', 'people', 'amp', 'consumer',\n",
       "       '19', 'covid', 'shopping', 's', 'online', 'need', 'time'],\n",
       "      dtype='<U27')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d7f75",
   "metadata": {},
   "source": [
    "Ahora que el vocabulario está configurado, la capa puede codificar el texto en índices. Los tensores de índices son rellenados con 0s para que tengan el tamaño de la secuencia más larga en el lote.\n",
    "\n",
    "Veamos un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c80a2ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1, 3767, 1478,   84,   11,  558,  850, 1290,   46,  145,  185,\n",
       "          10, 4834, 2673, 2727,   17,    5,  451,   35,   31, 2269,  265,\n",
       "        1656,  156, 1478, 7465,  424,    1,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [2350, 1818,    7,    3,   73,    2,    1,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [  38,    3, 1707,  850, 1697,  246, 1843, 4162, 3437, 7421, 1654,\n",
       "          34,  857,  688,    1,   19,   12,  410,    1,    1,    2,    1,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_example = encoder(example)[:3].numpy()\n",
    "encoded_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3741a6cf",
   "metadata": {},
   "source": [
    "Vemos que rellena con 0s hasta tener siempre un largo de 45.\n",
    "\n",
    "Con esta configuración, el proceso no es completamente reversible (no hay un mapeo uno a uno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5d873bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  b' ukenterprise speaking ur staff & amp ; asked shutdown affecting business . said lot people cancelling booking . checked online price gone . supply + demand ? picked another operator since ur keen putting peop'\n",
      "Round-trip:  [UNK] speaking ur staff amp asked shutdown affecting business said lot people cancelling booking checked online price gone supply demand picked another operator since ur keen putting [UNK]                 \n",
      "\n",
      "Original:  b'begun .  france  supermarket  coronavirus  lockdown http : //t.co/ogntm76ayc'\n",
      "Round-trip:  begun france supermarket coronavirus lockdown http [UNK]                                      \n",
      "\n",
      "Original:  b'due  coronavirus university shutdown , build small lab garage finish master project one student . turn prefect time consumer kid ? ? ?  earwigscience  irbi_tours http : //t.co/njgw2xuj0t'\n",
      "Round-trip:  due coronavirus university shutdown build small lab garage finish master project one student turn [UNK] time consumer kid [UNK] [UNK] http [UNK]                       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(3):\n",
    "  print(\"Original: \", example[n].numpy())\n",
    "  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af48ea7",
   "metadata": {},
   "source": [
    "Puede observarse que hay muchos tokens desconocidos ([UNK])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbbdb90",
   "metadata": {},
   "source": [
    "Finalmente, aplicaremos una capa de embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a9a0f1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x7f1224ab04f0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, # set the input shape; size of our vocabulary\n",
    "                                 output_dim=128, # set the size of the embedding vector\n",
    "                                 embeddings_initializer=\"uniform\", # default, initialize embedding vectors randomly\n",
    "                                 input_length=max_length # how long is each input\n",
    "                             )\n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf581ab",
   "metadata": {},
   "source": [
    "<a name=\"5\"> </a>\n",
    "## MODELOS\n",
    "\n",
    "Probaremos distinos modelos.\n",
    "\n",
    "...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "eb67012f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow._api.v2.sets' from '/home/marcos/.local/lib/python3.10/site-packages/tensorflow/_api/v2/sets/__init__.py'>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c1eecc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para guardar los resultados y comparar después\n",
    "\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "41080333",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE=(1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee0fc1b",
   "metadata": {},
   "source": [
    "<a name=\"5.1\"> </a>\n",
    "### Modelo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a1bcc6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model_1(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape, dtype=tf.string) # inputs are 1-dimensional strings\n",
    "    x = encoder(inputs) # turn the input text into numbers \n",
    "    x = embedding(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model\n",
    "    return model\n",
    "\n",
    "\n",
    "model_1 = build_model_1(INPUT_SHAPE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "74dadf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 45)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 45, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 128)              0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "acacf449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "515/515 [==============================] - 11s 21ms/step - loss: 0.5997 - accuracy: 0.6694 - precision: 0.6608 - recall: 0.9685 - val_loss: 0.5157 - val_accuracy: 0.7482 - val_precision: 0.7383 - val_recall: 0.9280\n",
      "Epoch 2/5\n",
      "515/515 [==============================] - 10s 19ms/step - loss: 0.4372 - accuracy: 0.8067 - precision: 0.7965 - recall: 0.9281 - val_loss: 0.4188 - val_accuracy: 0.8216 - val_precision: 0.8230 - val_recall: 0.9120\n",
      "Epoch 3/5\n",
      "515/515 [==============================] - 10s 19ms/step - loss: 0.3425 - accuracy: 0.8630 - precision: 0.8576 - recall: 0.9364 - val_loss: 0.3799 - val_accuracy: 0.8441 - val_precision: 0.8486 - val_recall: 0.9151\n",
      "Epoch 4/5\n",
      "515/515 [==============================] - 10s 20ms/step - loss: 0.2894 - accuracy: 0.8913 - precision: 0.8899 - recall: 0.9428 - val_loss: 0.3667 - val_accuracy: 0.8494 - val_precision: 0.8509 - val_recall: 0.9217\n",
      "Epoch 5/5\n",
      "515/515 [==============================] - 10s 19ms/step - loss: 0.2560 - accuracy: 0.9054 - precision: 0.9055 - recall: 0.9475 - val_loss: 0.3649 - val_accuracy: 0.8542 - val_precision: 0.8748 - val_recall: 0.8961\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy', 'Precision','Recall'])\n",
    "\n",
    "# Fit the model\n",
    "history_1 = model_1.fit(train_dataset,\n",
    "                        #train_labels, \n",
    "                        epochs=5,\n",
    "                        validation_data=validation_dataset)\n",
    "                        #callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                        #                                       experiment_name=\"model_1_dense\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "06393ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8296 - precision: 0.8404 - recall: 0.8656\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "score1 = model_1.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d592ce56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La precisión fue 83.0%, la precisión del 84.0% y el recall de 87.0%'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"La precisión fue {round(score1[1],2)*100}%, la precisión del {round(score1[2],2)*100}% y el recall de {round(score1[3],2)*100}%\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f27c720",
   "metadata": {},
   "source": [
    "Guardamos los resultados para poder comparar después\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f2baf67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_1_results = {\n",
    "    'name': 'Model 1',\n",
    "    'accuracy':score1[1],\n",
    "    'precision':score1[2],\n",
    "    'recall':score1[3],\n",
    "    'f1-score': (2*(score1[2]*score1[3]))/(score1[2]+score1[3])\n",
    "}\n",
    "\n",
    "\n",
    "results.append(model_1_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b232260e",
   "metadata": {},
   "source": [
    "#### Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bcfc3a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n",
      "pred: [[0.96849597]]\n",
      "Predicción: 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "En la inferencia, la entrada debe pasar previamente por el pre-procesamiento (en este ejemplo\n",
    "por preprocess_text y pre-process_text2); no hace falta que pase por las caspas de text vectorization\n",
    "y embedding pues son parte del modelo\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Texto de entrada para hacer una predicción\n",
    "input_text = \"this is very, very positive\"\n",
    "\n",
    "\n",
    "# pre-procesamiento\n",
    "input_text = preprocess_text(input_text)\n",
    "input_text = preprocess_text2(input_text)\n",
    "\n",
    "\n",
    "# predicción\n",
    "pred = model_1.predict(np.array([input_text]))\n",
    "\n",
    "print(f\"pred: {pred}\")\n",
    "\n",
    "\n",
    "# Convertir la salida a una predicción binaria (0 o 1)\n",
    "binary_prediction = 1 if pred[0, 0] > 0.5 else 0\n",
    "\n",
    "# Imprimir la predicción\n",
    "print(\"Predicción:\", binary_prediction)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7c541a",
   "metadata": {},
   "source": [
    "<a name=\"5.2\"> </a>\n",
    "### Modelo 2 : LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5253b3",
   "metadata": {},
   "source": [
    "Arquitectura típica de una RNN:\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/arq.png\" width=80%>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2cc37e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After embedding: (None, 45, 128)\n",
      "After LSTM cell: (None, 64)\n"
     ]
    }
   ],
   "source": [
    "def build_model_2(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape, dtype=\"string\")\n",
    "    x = encoder(inputs) # text vectorizer\n",
    "    x = embedding(x)\n",
    "    print(f\"After embedding: {x.shape}\")\n",
    "    # x = layers.LSTM(64, activation=\"tanh\", return_sequences=True)(x) # use return_sequences=True if you want to stack recurrent layers \n",
    "    # print(f\"After LSTM cell with return_sequences=True: {x.shape}\")\n",
    "    x = layers.LSTM(64, activation=\"tanh\")(x)\n",
    "    print(f\"After LSTM cell: {x.shape}\")\n",
    "    x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer to have on top of LSTM layer\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")\n",
    "    return model\n",
    "    \n",
    "\n",
    "model_2 = build_model_2(INPUT_SHAPE)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d4ba0a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 45)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 45, 128)           1280000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,333,633\n",
      "Trainable params: 1,333,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2607dd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "515/515 [==============================] - 22s 39ms/step - loss: 0.2557 - accuracy: 0.8995 - precision: 0.9076 - recall: 0.9345 - val_loss: 0.4010 - val_accuracy: 0.8483 - val_precision: 0.8877 - val_recall: 0.8683\n",
      "Epoch 2/5\n",
      "515/515 [==============================] - 20s 38ms/step - loss: 0.1962 - accuracy: 0.9283 - precision: 0.9361 - recall: 0.9502 - val_loss: 0.3579 - val_accuracy: 0.8509 - val_precision: 0.8877 - val_recall: 0.8731\n",
      "Epoch 3/5\n",
      "515/515 [==============================] - 20s 39ms/step - loss: 0.1660 - accuracy: 0.9426 - precision: 0.9501 - recall: 0.9586 - val_loss: 0.4400 - val_accuracy: 0.8507 - val_precision: 0.8527 - val_recall: 0.9215\n",
      "Epoch 4/5\n",
      "515/515 [==============================] - 19s 37ms/step - loss: 0.1356 - accuracy: 0.9532 - precision: 0.9570 - recall: 0.9687 - val_loss: 0.4589 - val_accuracy: 0.8518 - val_precision: 0.8692 - val_recall: 0.8994\n",
      "Epoch 5/5\n",
      "515/515 [==============================] - 19s 36ms/step - loss: 0.1101 - accuracy: 0.9613 - precision: 0.9639 - recall: 0.9746 - val_loss: 0.5645 - val_accuracy: 0.8511 - val_precision: 0.8685 - val_recall: 0.8990\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy', 'Precision','Recall'])\n",
    "\n",
    "# Fit the model\n",
    "history_2 = model_2.fit(train_dataset,\n",
    "                        epochs=5,\n",
    "                        validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "79bdbe56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6605 - accuracy: 0.8212 - precision: 0.8253 - recall: 0.8707\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "score2 = model_2.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d0b91c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_results = {\n",
    "    'name': 'Model 2',\n",
    "    'accuracy':score2[1],\n",
    "    'precision':score2[2],\n",
    "    'recall':score2[3],\n",
    "    'f1-score': (2*(score2[2]*score2[3]))/(score2[2]+score2[3])\n",
    "}\n",
    "\n",
    "\n",
    "results.append(model_2_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c3230a",
   "metadata": {},
   "source": [
    "<a name=\"5.3\"> </a>\n",
    "### Modelo 3 : GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4e9fec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_3(input_shape):\n",
    "    # Build an RNN using the GRU cell\n",
    "    inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "    x = encoder(inputs)\n",
    "    x = embedding(x)\n",
    "    # x = layers.GRU(64, activation=\"tanh\", return_sequences=True)(x) # return_sequences=True is required for stacking recurrent cells\n",
    "    # print(x.shape)\n",
    "    x = layers.GRU(64, activation=\"tanh\")(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model= tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")\n",
    "    return model\n",
    "\n",
    "\n",
    "model_3 = build_model_3(INPUT_SHAPE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1d269a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "515/515 [==============================] - 20s 35ms/step - loss: 0.3153 - accuracy: 0.8508 - precision: 0.8297 - recall: 0.9581 - val_loss: 0.5551 - val_accuracy: 0.8315 - val_precision: 0.9039 - val_recall: 0.8188\n",
      "Epoch 2/5\n",
      "515/515 [==============================] - 18s 34ms/step - loss: 0.1216 - accuracy: 0.9619 - precision: 0.9664 - recall: 0.9729 - val_loss: 0.4588 - val_accuracy: 0.8506 - val_precision: 0.8710 - val_recall: 0.8946\n",
      "Epoch 3/5\n",
      "515/515 [==============================] - 17s 34ms/step - loss: 0.0893 - accuracy: 0.9719 - precision: 0.9735 - recall: 0.9817 - val_loss: 0.5964 - val_accuracy: 0.8518 - val_precision: 0.8714 - val_recall: 0.8963\n",
      "Epoch 4/5\n",
      "515/515 [==============================] - 18s 35ms/step - loss: 0.0719 - accuracy: 0.9759 - precision: 0.9781 - recall: 0.9835 - val_loss: 0.6087 - val_accuracy: 0.8460 - val_precision: 0.8626 - val_recall: 0.8977\n",
      "Epoch 5/5\n",
      "515/515 [==============================] - 19s 37ms/step - loss: 0.0633 - accuracy: 0.9786 - precision: 0.9797 - recall: 0.9863 - val_loss: 0.6441 - val_accuracy: 0.8517 - val_precision: 0.8654 - val_recall: 0.9044\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model_3.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy', 'Precision','Recall'])\n",
    "\n",
    "# Fit the model\n",
    "history_3 = model_3.fit(train_dataset,\n",
    "                        epochs=5,\n",
    "                        validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "013865ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 7ms/step - loss: 0.7627 - accuracy: 0.8189 - precision: 0.8149 - recall: 0.8827\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "score3 = model_3.evaluate(test_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5c9ae9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_results = {\n",
    "    'name': 'Model 3',\n",
    "    'accuracy':score3[1],\n",
    "    'precision':score3[2],\n",
    "    'recall':score3[3],\n",
    "    'f1-score': (2*(score3[2]*score3[3]))/(score3[2]+score3[3])\n",
    "}\n",
    "\n",
    "\n",
    "results.append(model_3_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfbf2c5",
   "metadata": {},
   "source": [
    "<a name=\"5.4\"> </a>\n",
    "### Modelo 4 : Bidirectional RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142f56ab",
   "metadata": {},
   "source": [
    "<img src=\"images/model4.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "850e46de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_4(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape, dtype=\"string\")\n",
    "    x = encoder(inputs)\n",
    "    x = embedding(x)\n",
    "    # x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # return_sequences=True required for stacking RNN layers\n",
    "    x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\")\n",
    "    return model\n",
    "\n",
    "model_4 = build_model_4(INPUT_SHAPE)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3f6c3673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "515/515 [==============================] - 32s 56ms/step - loss: 0.1440 - accuracy: 0.9498 - precision: 0.9553 - recall: 0.9648 - val_loss: 0.5187 - val_accuracy: 0.8502 - val_precision: 0.8662 - val_recall: 0.9006\n",
      "Epoch 2/5\n",
      "515/515 [==============================] - 29s 55ms/step - loss: 0.0774 - accuracy: 0.9745 - precision: 0.9752 - recall: 0.9843 - val_loss: 0.6640 - val_accuracy: 0.8454 - val_precision: 0.8847 - val_recall: 0.8667\n",
      "Epoch 3/5\n",
      "515/515 [==============================] - 27s 53ms/step - loss: 0.0577 - accuracy: 0.9807 - precision: 0.9805 - recall: 0.9887 - val_loss: 0.7481 - val_accuracy: 0.8392 - val_precision: 0.8438 - val_recall: 0.9130\n",
      "Epoch 4/5\n",
      "515/515 [==============================] - 28s 55ms/step - loss: 0.0407 - accuracy: 0.9865 - precision: 0.9874 - recall: 0.9911 - val_loss: 0.8414 - val_accuracy: 0.8480 - val_precision: 0.8677 - val_recall: 0.8944\n",
      "Epoch 5/5\n",
      "515/515 [==============================] - 28s 54ms/step - loss: 0.0320 - accuracy: 0.9898 - precision: 0.9914 - recall: 0.9922 - val_loss: 0.9937 - val_accuracy: 0.8293 - val_precision: 0.8269 - val_recall: 0.9211\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model_4.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy', 'Precision','Recall'])\n",
    "\n",
    "# Fit the model\n",
    "history_4 = model_4.fit(train_dataset,\n",
    "                        epochs=5,\n",
    "                        validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "db277251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 12ms/step - loss: 1.2057 - accuracy: 0.7952 - precision: 0.7760 - recall: 0.9007\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "score4 = model_4.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a25af72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4_results = {\n",
    "    'name': 'Model 4',\n",
    "    'accuracy':score4[1],\n",
    "    'precision':score4[2],\n",
    "    'recall':score4[3],\n",
    "    'f1-score': (2*(score3[2]*score3[3]))/(score3[2]+score3[3])\n",
    "}\n",
    "\n",
    "\n",
    "results.append(model_4_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82409cee",
   "metadata": {},
   "source": [
    "<a name=\"5.5\"> </a>\n",
    "### Modelo 5 : Stacking layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff19c816",
   "metadata": {},
   "source": [
    "<img src='images/model5.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "72143fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# text vect. en la foto de arriba y la dense\n",
    "\n",
    "def build_model_5(input_shape,name):\n",
    "    inputs = layers.Input(shape=input_shape, dtype='string')\n",
    "    x = encoder(inputs)\n",
    "    x = embedding(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(32))(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    # dropout?\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs, outputs, name=name)\n",
    "    return model\n",
    "    \n",
    "\n",
    "model_5 = build_model_5(INPUT_SHAPE, 'model_5')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "601a2472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "515/515 [==============================] - 47s 80ms/step - loss: 0.1044 - accuracy: 0.9643 - precision: 0.9689 - recall: 0.9741 - val_loss: 0.7613 - val_accuracy: 0.8378 - val_precision: 0.8772 - val_recall: 0.8625\n",
      "Epoch 2/5\n",
      "515/515 [==============================] - 39s 75ms/step - loss: 0.0372 - accuracy: 0.9868 - precision: 0.9877 - recall: 0.9913 - val_loss: 0.8431 - val_accuracy: 0.8339 - val_precision: 0.8641 - val_recall: 0.8729\n",
      "Epoch 3/5\n",
      "515/515 [==============================] - 38s 74ms/step - loss: 0.0256 - accuracy: 0.9920 - precision: 0.9933 - recall: 0.9940 - val_loss: 0.9215 - val_accuracy: 0.8347 - val_precision: 0.8465 - val_recall: 0.9000\n",
      "Epoch 4/5\n",
      "515/515 [==============================] - 36s 70ms/step - loss: 0.0232 - accuracy: 0.9922 - precision: 0.9934 - recall: 0.9941 - val_loss: 0.9269 - val_accuracy: 0.8390 - val_precision: 0.8656 - val_recall: 0.8805\n",
      "Epoch 5/5\n",
      "515/515 [==============================] - 39s 77ms/step - loss: 0.0178 - accuracy: 0.9946 - precision: 0.9954 - recall: 0.9960 - val_loss: 1.0238 - val_accuracy: 0.8378 - val_precision: 0.8777 - val_recall: 0.8619\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model_5.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy', 'Precision','Recall'])\n",
    "\n",
    "# Fit the model\n",
    "history_5 = model_5.fit(train_dataset,\n",
    "                        epochs=5,\n",
    "                        validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "70886d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 18ms/step - loss: 1.1971 - accuracy: 0.8117 - precision: 0.8363 - recall: 0.8328\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "score5 = model_5.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2f190203",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5_results = {\n",
    "    'name': 'Model 5',\n",
    "    'accuracy':score5[1],\n",
    "    'precision':score5[2],\n",
    "    'recall':score5[3],\n",
    "    'f1-score': (2*(score5[2]*score5[3]))/(score5[2]+score5[3])\n",
    "}\n",
    "\n",
    "\n",
    "results.append(model_5_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7335bb64",
   "metadata": {},
   "source": [
    "<a name=\"5.6\"> </a>\n",
    "### Modelo 6 : Conv1D\n",
    "\n",
    "We've seen before how convolutional neural networks can be used for images but they can also be used for text.\n",
    "\n",
    "Previously we've used the layer Conv2D (which is great for images with (height, width)).\n",
    "\n",
    "But if we want to use convolutional layers for sequences (e.g. text) we need to use Conv1D: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D\n",
    "\n",
    "For more of a deep dive into what goes on behind the scenes in a CNN for text (or sequences) see the paper: https://arxiv.org/abs/1809.08037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a511b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_6(input_shape,name):\n",
    "    inputs = layers.Input(shape=input_shape, dtype='string')\n",
    "    x = encoder(inputs)\n",
    "    x = embedding(x)\n",
    "    x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
    "    x = layers.GlobalMaxPool1D()(x)\n",
    "    # x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")(x)\n",
    "    model = tf.keras.Model(inputs, outputs, name=name)\n",
    "    return model\n",
    "    \n",
    "    \n",
    "\n",
    "model_6 = build_model_6(INPUT_SHAPE, 'model_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7ca9889d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 45)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 45, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 41, 32)            20512     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 32)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,300,545\n",
      "Trainable params: 1,300,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8a67fbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "515/515 [==============================] - 12s 21ms/step - loss: 0.2270 - accuracy: 0.9203 - precision: 0.9301 - recall: 0.9434 - val_loss: 0.3965 - val_accuracy: 0.8536 - val_precision: 0.8923 - val_recall: 0.8721\n",
      "Epoch 2/5\n",
      "515/515 [==============================] - 13s 24ms/step - loss: 0.1648 - accuracy: 0.9442 - precision: 0.9515 - recall: 0.9598 - val_loss: 0.4309 - val_accuracy: 0.8553 - val_precision: 0.8754 - val_recall: 0.8973\n",
      "Epoch 3/5\n",
      "515/515 [==============================] - 11s 22ms/step - loss: 0.1124 - accuracy: 0.9669 - precision: 0.9715 - recall: 0.9757 - val_loss: 0.4923 - val_accuracy: 0.8513 - val_precision: 0.8737 - val_recall: 0.8923\n",
      "Epoch 4/5\n",
      "515/515 [==============================] - 11s 21ms/step - loss: 0.0697 - accuracy: 0.9833 - precision: 0.9855 - recall: 0.9879 - val_loss: 0.5599 - val_accuracy: 0.8465 - val_precision: 0.8717 - val_recall: 0.8859\n",
      "Epoch 5/5\n",
      "515/515 [==============================] - 12s 23ms/step - loss: 0.0407 - accuracy: 0.9918 - precision: 0.9927 - recall: 0.9942 - val_loss: 0.6467 - val_accuracy: 0.8414 - val_precision: 0.8690 - val_recall: 0.8801\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy', 'Precision','Recall'])\n",
    "\n",
    "# Fit the model\n",
    "history_6 = model_6.fit(train_dataset,\n",
    "                        #batch_size=BATCH_SIZE,\n",
    "                        epochs=5,\n",
    "                        validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "767937e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 3ms/step - loss: 0.7445 - accuracy: 0.8025 - precision: 0.8177 - recall: 0.8411\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "score6 = model_6.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b0c2e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6_results = {\n",
    "    'name': 'Model 6',\n",
    "    'accuracy':score6[1],\n",
    "    'precision':score6[2],\n",
    "    'recall':score6[3],\n",
    "    'f1-score': (2*(score6[2]*score6[3]))/(score6[2]+score6[3])\n",
    "}\n",
    "\n",
    "\n",
    "results.append(model_6_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c20d17",
   "metadata": {},
   "source": [
    "<a name=\"5.7\"> </a>\n",
    "### Model 7: TensorFlow Hub Pretrained Sentence Encoder\n",
    "\n",
    "Now we've built a few of our own models, let's try and use transfer learning for NLP, specifically using TensorFlow Hub's Universal Sentence Encoder: https://tfhub.dev/google/universal-sentence-encoder/4\n",
    "\n",
    "See how the USE was created here: https://arxiv.org/abs/1803.11175\n",
    "\n",
    "📖 **Resource:** TensorFlow Hub is a great resource for many pretrained models but HuggingFace is also another incredible resource for many pretrained NLP models (using HuggingFace model is beyond the scope of this course but it is definitely something you should be familiar with in the NLP space): https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "23ef7e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keras Layer using the USE pretrained layer from tensorflow hub\n",
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        input_shape=[],\n",
    "                                        dtype=tf.string,\n",
    "                                        trainable=False,\n",
    "                                        name=\"USE\")\n",
    "\n",
    "# se encarga de text vectorization y embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "39718f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 1)]               0         \n",
      "                                                                 \n",
      " tf.compat.v1.squeeze_3 (TFO  (None,)                  0         \n",
      " pLambda)                                                        \n",
      "                                                                 \n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                32832     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model_7(input_shape,name):\n",
    "    # Entrada del modelo\n",
    "    input_layer = layers.Input(shape=input_shape, dtype=tf.string, name=\"input_layer\")\n",
    "    squeezed_input = tf.squeeze(input_layer, axis=-1)\n",
    "    # Capa de codificación de oraciones\n",
    "    sentence_encoding = sentence_encoder_layer(squeezed_input)\n",
    "    # Capa completamente conectada con activación ReLU\n",
    "    dense_layer = layers.Dense(64, activation=\"relu\")(sentence_encoding)\n",
    "    # Capa de salida con activación sigmoide\n",
    "    output_layer = layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")(dense_layer)\n",
    "    # Crear el modelo funcional\n",
    "    model = Model(inputs=input_layer, outputs=output_layer, name=name)\n",
    "    return model\n",
    "\n",
    "\n",
    "model_7 = build_model_7(INPUT_SHAPE,'model_7')\n",
    "\n",
    "\n",
    "\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c96fff12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "515/515 [==============================] - 9s 13ms/step - loss: 0.5186 - accuracy: 0.7421 - precision: 0.7548 - recall: 0.8702 - val_loss: 0.4868 - val_accuracy: 0.7674 - val_precision: 0.7798 - val_recall: 0.8774\n",
      "Epoch 2/5\n",
      "515/515 [==============================] - 6s 12ms/step - loss: 0.4786 - accuracy: 0.7686 - precision: 0.7940 - recall: 0.8506 - val_loss: 0.4816 - val_accuracy: 0.7657 - val_precision: 0.7948 - val_recall: 0.8451\n",
      "Epoch 3/5\n",
      "515/515 [==============================] - 6s 11ms/step - loss: 0.4730 - accuracy: 0.7734 - precision: 0.8002 - recall: 0.8499 - val_loss: 0.4811 - val_accuracy: 0.7680 - val_precision: 0.7990 - val_recall: 0.8426\n",
      "Epoch 4/5\n",
      "515/515 [==============================] - 6s 11ms/step - loss: 0.4691 - accuracy: 0.7749 - precision: 0.8015 - recall: 0.8506 - val_loss: 0.4807 - val_accuracy: 0.7732 - val_precision: 0.7840 - val_recall: 0.8818\n",
      "Epoch 5/5\n",
      "515/515 [==============================] - 6s 12ms/step - loss: 0.4638 - accuracy: 0.7769 - precision: 0.8023 - recall: 0.8535 - val_loss: 0.4756 - val_accuracy: 0.7704 - val_precision: 0.8033 - val_recall: 0.8402\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model_7.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy', 'Precision','Recall'])\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "history_7 = model_7.fit(train_dataset,\n",
    "                        epochs=5,\n",
    "                        validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "71c7fb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5155 - accuracy: 0.7438 - precision: 0.7635 - recall: 0.7977\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "score7 = model_7.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "47e671d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7_results = {\n",
    "    'name': 'Model 7',\n",
    "    'accuracy':score7[1],\n",
    "    'precision':score7[2],\n",
    "    'recall':score7[3],\n",
    "    'f1-score': (2*(score7[2]*score7[3]))/(score7[2]+score7[3])\n",
    "}\n",
    "\n",
    "\n",
    "results.append(model_7_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9befb56",
   "metadata": {},
   "source": [
    "### Comparando los modelos y quedándonos con el mejor para afinar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "41b0c64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 1</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.840359</td>\n",
       "      <td>0.865589</td>\n",
       "      <td>0.852787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 2</td>\n",
       "      <td>0.821222</td>\n",
       "      <td>0.825306</td>\n",
       "      <td>0.870670</td>\n",
       "      <td>0.847381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 3</td>\n",
       "      <td>0.818852</td>\n",
       "      <td>0.814925</td>\n",
       "      <td>0.882679</td>\n",
       "      <td>0.847450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 4</td>\n",
       "      <td>0.795155</td>\n",
       "      <td>0.775965</td>\n",
       "      <td>0.900693</td>\n",
       "      <td>0.847450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model 5</td>\n",
       "      <td>0.811743</td>\n",
       "      <td>0.836271</td>\n",
       "      <td>0.832794</td>\n",
       "      <td>0.834529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Model 6</td>\n",
       "      <td>0.802528</td>\n",
       "      <td>0.817692</td>\n",
       "      <td>0.841109</td>\n",
       "      <td>0.829235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Model 7</td>\n",
       "      <td>0.743813</td>\n",
       "      <td>0.763484</td>\n",
       "      <td>0.797691</td>\n",
       "      <td>0.780212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  accuracy  precision    recall  f1-score\n",
       "0  Model 1  0.829647   0.840359  0.865589  0.852787\n",
       "1  Model 2  0.821222   0.825306  0.870670  0.847381\n",
       "2  Model 3  0.818852   0.814925  0.882679  0.847450\n",
       "3  Model 4  0.795155   0.775965  0.900693  0.847450\n",
       "4  Model 5  0.811743   0.836271  0.832794  0.834529\n",
       "5  Model 6  0.802528   0.817692  0.841109  0.829235\n",
       "6  Model 7  0.743813   0.763484  0.797691  0.780212"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine model results into a DataFrame\n",
    "all_model_results = pd.DataFrame(results)\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "51832f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\n",
    "# Configurar el tamaño de la figura\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "\n",
    "# Configurar el gráfico de barras\n",
    "bar_width = 0.2\n",
    "bar_positions = range(len(df['name']))\n",
    "colors = ['blue', 'orange', 'green', 'red']\n",
    "\n",
    "# Crear barras para cada métrica\n",
    "plt.bar(bar_positions, df['accuracy'], width=bar_width, label='Accuracy', color=colors[0])\n",
    "plt.bar([pos + bar_width for pos in bar_positions], df['precision'], width=bar_width, label='Precision', color=colors[1])\n",
    "plt.bar([pos + 2*bar_width for pos in bar_positions], df['recall'], width=bar_width, label='Recall', color=colors[2])\n",
    "plt.bar([pos + 3*bar_width for pos in bar_positions], df['f1-score'], width=bar_width, label='F1-score', color=colors[3])\n",
    "\n",
    "\n",
    "\n",
    "# Añadir etiquetas y título\n",
    "plt.xlabel('Model',fontweight='bold')\n",
    "plt.ylabel('Scores',fontweight='bold')\n",
    "plt.title('Comparison of Metrics for Different Models',fontweight='bold')\n",
    "plt.xticks([pos + 1.5*bar_width for pos in bar_positions], df['name'])\n",
    "\n",
    "# Añadir leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el gráfico de barras\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d121a287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort model results by f1-score\n",
    "df.sort_values(\"f1-score\", ascending=False)[\"f1-score\"].plot(kind=\"bar\", figsize=(10, 7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1d38eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_max = all_model_results['f1-score'].idxmax()\n",
    "\n",
    "best_model = all_model_results['name'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "69ec54b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El mejor modelo siguiendo el criterio de mayor F1-score es Model 1'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"El mejor modelo siguiendo el criterio de mayor F1-score es {best_model}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39796c0c",
   "metadata": {},
   "source": [
    "### Ajuste de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e52a59",
   "metadata": {},
   "source": [
    "Probaremos con diferentes valores para la tasa de aprendizaje y por supuesto entrenaremos por más epochs.\n",
    "También usaremos callbacks, como Early Stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a3a9851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(keras_tuner.HyperModel) :\n",
    "     def build(self, hp,input_shape=INPUT_SHAPE):\n",
    "        inputs = layers.Input(shape=input_shape, dtype=tf.string)\n",
    "        x = encoder(inputs)\n",
    "        x = embedding(x)\n",
    "        x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "        outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "        model = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")\n",
    "        # compile\n",
    "        model.compile(optimizer=hp.Choice('optim',['adam','adamax','sgd']),\n",
    "                      loss=\"binary_crossentropy\",\n",
    "                      metrics = ['accuracy','Precision','Recall'])\n",
    "        \n",
    "        # A way to optimize the learning rate while also trying different optimizers\n",
    "        learning_rate = hp.Choice('lr', [ 0.03, 0.01, 0.003])\n",
    "        K.set_value(model.optimizer.learning_rate, learning_rate)\n",
    "        # retorno\n",
    "        return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda746d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.BayesianOptimization(\n",
    "                        hypermodel=MyHyperModel(),\n",
    "                        objective = \"val_accuracy\",\n",
    "                        max_trials =10, #max candidates to test\n",
    "                        overwrite=True,\n",
    "                        directory='search_dir',\n",
    "                        project_name='sentiment_analysis')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875930c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x=train_dataset, \n",
    "             epochs=8,\n",
    "             validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c777a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mejor modelo\n",
    "\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "final_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "final_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d0b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\",save_best_only=True),\n",
    "]\n",
    "\n",
    "final_history = final_model.fit(\n",
    "                  train_dataset, \n",
    "                  validation_data=validation_dataset,\n",
    "                  epochs=100, \n",
    "                  verbose=0,\n",
    "                  batch_size=batch_size,                  \n",
    "                  callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8014201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "final_scores = final_.evaluate(test_data)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
